# CronAI Configuration Example with Model-Specific Parameters
# Format: timestamp model prompt.md response_processor [variables] [model_params:...]
# Variables format: key1=value1,key2=value2,...
# Model parameters format: model_params:param1=value1,param2=value2,...
# Model-specific parameters format: model_params:model_name.param=value,...

# ============================================================================
# MVP PROCESSORS - Examples with Model-Specific Parameters
# ============================================================================

# OpenAI-specific configuration with file output
0 8 * * * openai product_manager file-/var/log/cronai/product.log model_params:openai.model=gpt-4-turbo

# Claude-specific configuration with file output (v0.0.2+ supports Claude 3, 3.5, and 4)
0 9 * * 1 claude weekly_report file-/var/log/cronai/weekly.log reportType=Weekly,date={{CURRENT_DATE}} model_params:claude.model=claude-3-opus-20240229

# Claude 4 models (v0.0.2+) - using aliases
0 9 * * 1 claude weekly_report file-/var/log/cronai/weekly.log reportType=Weekly,date={{CURRENT_DATE}} model_params:claude.model=opus

# Claude 4 models (v0.0.2+) - using full model names
0 9 * * 1 claude weekly_report file-/var/log/cronai/weekly.log reportType=Weekly,date={{CURRENT_DATE}} model_params:claude.model=claude-4-opus-latest

# Claude 3.5 models (v0.0.2+)
0 9 * * 1 claude weekly_report file-/var/log/cronai/weekly.log reportType=Weekly,date={{CURRENT_DATE}} model_params:claude.model=3.5-sonnet

# Gemini-specific configuration with console output
*/15 * * * * gemini system_health console cluster=Primary model_params:gemini.model=gemini-pro

# Mixed common and model-specific parameters with GitHub issue creation
0 22 * * * claude test_prompt github-issue:myorg/myrepo model_params:temperature=0.5,max_tokens=2000,claude.model=claude-3-haiku-20240307

# Multiple model configuration in one file
# Each task uses its own model with appropriate configuration

# Morning health check with Gemini - save to file
0 8 * * * gemini system_health file-/var/log/cronai/health.log model_params:temperature=0.1,gemini.model=gemini-pro

# Midday report with Claude - output to console
0 12 * * * claude product_manager console model_params:claude.model=claude-3-sonnet-20240229

# Evening analysis with OpenAI - create GitHub issue
# Issue will have formatted title and body with model details
0 17 * * * openai weekly_report github-issue:myorg/myrepo model_params:temperature=0.7,openai.model=gpt-4

# Comment on specific issue with detailed model configuration
0 14 * * * claude review_comments github-comment:myorg/myrepo#55 model_params:claude.model=claude-3-opus-20240229

# ============================================================================
# POST-MVP FEATURES (Coming Soon)
# ============================================================================

# PLANNED: System message customization (post-MVP)
# 0 8 * * * openai product_manager slack-pm-channel model_params:openai.model=gpt-4,openai.system_message=You are a product manager assistant.

# PLANNED: Claude system message (post-MVP)
# 0 9 * * 1 claude weekly_report email-team@company.com model_params:claude.model=claude-3-opus-20240229,claude.system_message=You are a business analyst.

# PLANNED: Gemini safety settings (post-MVP)
# */15 * * * * gemini system_health webhook-monitoring model_params:gemini.model=gemini-pro,gemini.safety_setting=harmful=block

# PLANNED: Mixed common and model-specific parameters with email
# 0 22 * * * claude test_prompt email-dev@company.com model_params:temperature=0.5,claude.model=claude-3-haiku-20240307,claude.system_message=You are a systems analyst.